{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "# Train Neural Network Potential To Both Energies and Forces\n",
        "\n",
        "We have seen how to train a neural network potential by manually writing\n",
        "training loop in `training-example`. This tutorial shows how to modify\n",
        "that script to train to force.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most part of the script are the same as `training-example`, we will omit\n",
        "the comments for these parts. Please refer to `training-example` for more\n",
        "information\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> loading /Users/sergiortizropero/Programming/ASE/ase_ani/test_notebooks/../dataset/ani-1x/sample.h5, total molecules: 6\n",
            "6/6  [==============================] - 0.1s\n",
            "=> loading /Users/sergiortizropero/Programming/ASE/ase_ani/test_notebooks/../dataset/ani-1x/sample.h5, total molecules: 6\n",
            "6/6  [==============================] - 0.1s\n",
            "Self atomic energies:  tensor([-19.3542, -19.3542, -54.7122, -75.1628], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchani\n",
        "import os\n",
        "import math\n",
        "import torch.utils.tensorboard\n",
        "import tqdm\n",
        "\n",
        "# helper function to convert energy unit from Hartree to kcal/mol\n",
        "from torchani.units import hartree2kcalmol\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "Rcr = 5.2000e+00\n",
        "Rca = 3.5000e+00\n",
        "EtaR = torch.tensor([1.6000000e+01], device=device)\n",
        "ShfR = torch.tensor([9.0000000e-01, 1.1687500e+00, 1.4375000e+00, 1.7062500e+00, 1.9750000e+00, 2.2437500e+00, 2.5125000e+00, 2.7812500e+00, 3.0500000e+00, 3.3187500e+00, 3.5875000e+00, 3.8562500e+00, 4.1250000e+00, 4.3937500e+00, 4.6625000e+00, 4.9312500e+00], device=device)\n",
        "Zeta = torch.tensor([3.2000000e+01], device=device)\n",
        "ShfZ = torch.tensor([1.9634954e-01, 5.8904862e-01, 9.8174770e-01, 1.3744468e+00, 1.7671459e+00, 2.1598449e+00, 2.5525440e+00, 2.9452431e+00], device=device)\n",
        "EtaA = torch.tensor([8.0000000e+00], device=device)\n",
        "ShfA = torch.tensor([9.0000000e-01, 1.5500000e+00, 2.2000000e+00, 2.8500000e+00], device=device)\n",
        "species_order = ['H', 'C', 'N', 'O']\n",
        "num_species = len(species_order)\n",
        "aev_computer = torchani.AEVComputer(Rcr, Rca, EtaR, ShfR, EtaA, Zeta, ShfA, ShfZ, num_species)\n",
        "energy_shifter = torchani.utils.EnergyShifter(None)\n",
        "\n",
        "\n",
        "try:\n",
        "    path = os.path.dirname(os.path.realpath(__file__))\n",
        "except NameError:\n",
        "    path = os.getcwd()\n",
        "dspath = os.path.join(path, '../dataset/ani-1x/sample.h5')\n",
        "\n",
        "batch_size = 2560\n",
        "\n",
        "training, validation = torchani.data.load(\n",
        "    dspath,\n",
        "    additional_properties=('forces',)\n",
        ").subtract_self_energies(energy_shifter, species_order).species_to_indices(species_order).shuffle().split(0.8, None)\n",
        "\n",
        "training = training.collate(batch_size).cache()\n",
        "validation = validation.collate(batch_size).cache()\n",
        "\n",
        "print('Self atomic energies: ', energy_shifter.self_energies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code to define networks, optimizers, are mostly the same\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANIModel(\n",
            "  (0): Sequential(\n",
            "    (0): Linear(in_features=384, out_features=160, bias=True)\n",
            "    (1): CELU(alpha=0.1)\n",
            "    (2): Linear(in_features=160, out_features=128, bias=True)\n",
            "    (3): CELU(alpha=0.1)\n",
            "    (4): Linear(in_features=128, out_features=96, bias=True)\n",
            "    (5): CELU(alpha=0.1)\n",
            "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Linear(in_features=384, out_features=144, bias=True)\n",
            "    (1): CELU(alpha=0.1)\n",
            "    (2): Linear(in_features=144, out_features=112, bias=True)\n",
            "    (3): CELU(alpha=0.1)\n",
            "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
            "    (5): CELU(alpha=0.1)\n",
            "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
            "    (1): CELU(alpha=0.1)\n",
            "    (2): Linear(in_features=128, out_features=112, bias=True)\n",
            "    (3): CELU(alpha=0.1)\n",
            "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
            "    (5): CELU(alpha=0.1)\n",
            "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
            "    (1): CELU(alpha=0.1)\n",
            "    (2): Linear(in_features=128, out_features=112, bias=True)\n",
            "    (3): CELU(alpha=0.1)\n",
            "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
            "    (5): CELU(alpha=0.1)\n",
            "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "aev_dim = aev_computer.aev_length\n",
        "\n",
        "H_network = torch.nn.Sequential(\n",
        "    torch.nn.Linear(aev_dim, 160),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(160, 128),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(128, 96),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(96, 1)\n",
        ")\n",
        "\n",
        "C_network = torch.nn.Sequential(\n",
        "    torch.nn.Linear(aev_dim, 144),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(144, 112),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(112, 96),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(96, 1)\n",
        ")\n",
        "\n",
        "N_network = torch.nn.Sequential(\n",
        "    torch.nn.Linear(aev_dim, 128),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(128, 112),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(112, 96),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(96, 1)\n",
        ")\n",
        "\n",
        "O_network = torch.nn.Sequential(\n",
        "    torch.nn.Linear(aev_dim, 128),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(128, 112),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(112, 96),\n",
        "    torch.nn.CELU(0.1),\n",
        "    torch.nn.Linear(96, 1)\n",
        ")\n",
        "\n",
        "nn = torchani.ANIModel([H_network, C_network, N_network, O_network])\n",
        "print(nn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the weights and biases.\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Pytorch default initialization for the weights and biases in linear layers\n",
        "  is Kaiming uniform. See: `TORCH.NN.MODULES.LINEAR`_\n",
        "  We initialize the weights similarly but from the normal distribution.\n",
        "  The biases were initialized to zero.</p></div>\n",
        "\n",
        "  https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ANIModel(\n",
              "  (0): Sequential(\n",
              "    (0): Linear(in_features=384, out_features=160, bias=True)\n",
              "    (1): CELU(alpha=0.1)\n",
              "    (2): Linear(in_features=160, out_features=128, bias=True)\n",
              "    (3): CELU(alpha=0.1)\n",
              "    (4): Linear(in_features=128, out_features=96, bias=True)\n",
              "    (5): CELU(alpha=0.1)\n",
              "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
              "  )\n",
              "  (1): Sequential(\n",
              "    (0): Linear(in_features=384, out_features=144, bias=True)\n",
              "    (1): CELU(alpha=0.1)\n",
              "    (2): Linear(in_features=144, out_features=112, bias=True)\n",
              "    (3): CELU(alpha=0.1)\n",
              "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
              "    (5): CELU(alpha=0.1)\n",
              "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
              "  )\n",
              "  (2): Sequential(\n",
              "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
              "    (1): CELU(alpha=0.1)\n",
              "    (2): Linear(in_features=128, out_features=112, bias=True)\n",
              "    (3): CELU(alpha=0.1)\n",
              "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
              "    (5): CELU(alpha=0.1)\n",
              "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
              "  )\n",
              "  (3): Sequential(\n",
              "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
              "    (1): CELU(alpha=0.1)\n",
              "    (2): Linear(in_features=128, out_features=112, bias=True)\n",
              "    (3): CELU(alpha=0.1)\n",
              "    (4): Linear(in_features=112, out_features=96, bias=True)\n",
              "    (5): CELU(alpha=0.1)\n",
              "    (6): Linear(in_features=96, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def init_params(m):\n",
        "    if isinstance(m, torch.nn.Linear):\n",
        "        torch.nn.init.kaiming_normal_(m.weight, a=1.0)\n",
        "        torch.nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "nn.apply(init_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now create a pipeline of AEV Computer --> Neural Networks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = torchani.nn.Sequential(aev_computer, nn).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we will use Adam with weight decay for the weights and Stochastic Gradient\n",
        "Descent for biases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "AdamW = torch.optim.AdamW([\n",
        "    # H networks\n",
        "    {'params': [H_network[0].weight]},\n",
        "    {'params': [H_network[2].weight], 'weight_decay': 0.00001},\n",
        "    {'params': [H_network[4].weight], 'weight_decay': 0.000001},\n",
        "    {'params': [H_network[6].weight]},\n",
        "    # C networks\n",
        "    {'params': [C_network[0].weight]},\n",
        "    {'params': [C_network[2].weight], 'weight_decay': 0.00001},\n",
        "    {'params': [C_network[4].weight], 'weight_decay': 0.000001},\n",
        "    {'params': [C_network[6].weight]},\n",
        "    # N networks\n",
        "    {'params': [N_network[0].weight]},\n",
        "    {'params': [N_network[2].weight], 'weight_decay': 0.00001},\n",
        "    {'params': [N_network[4].weight], 'weight_decay': 0.000001},\n",
        "    {'params': [N_network[6].weight]},\n",
        "    # O networks\n",
        "    {'params': [O_network[0].weight]},\n",
        "    {'params': [O_network[2].weight], 'weight_decay': 0.00001},\n",
        "    {'params': [O_network[4].weight], 'weight_decay': 0.000001},\n",
        "    {'params': [O_network[6].weight]},\n",
        "])\n",
        "\n",
        "SGD = torch.optim.SGD([\n",
        "    # H networks\n",
        "    {'params': [H_network[0].bias]},\n",
        "    {'params': [H_network[2].bias]},\n",
        "    {'params': [H_network[4].bias]},\n",
        "    {'params': [H_network[6].bias]},\n",
        "    # C networks\n",
        "    {'params': [C_network[0].bias]},\n",
        "    {'params': [C_network[2].bias]},\n",
        "    {'params': [C_network[4].bias]},\n",
        "    {'params': [C_network[6].bias]},\n",
        "    # N networks\n",
        "    {'params': [N_network[0].bias]},\n",
        "    {'params': [N_network[2].bias]},\n",
        "    {'params': [N_network[4].bias]},\n",
        "    {'params': [N_network[6].bias]},\n",
        "    # O networks\n",
        "    {'params': [O_network[0].bias]},\n",
        "    {'params': [O_network[2].bias]},\n",
        "    {'params': [O_network[4].bias]},\n",
        "    {'params': [O_network[6].bias]},\n",
        "], lr=1e-3)\n",
        "\n",
        "AdamW_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(AdamW, factor=0.5, patience=100, threshold=0)\n",
        "SGD_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(SGD, factor=0.5, patience=100, threshold=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This part of the code is also the same\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "latest_checkpoint = 'force-training-latest.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resume training from previously saved checkpoints:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if os.path.isfile(latest_checkpoint):\n",
        "    checkpoint = torch.load(latest_checkpoint)\n",
        "    nn.load_state_dict(checkpoint['nn'])\n",
        "    AdamW.load_state_dict(checkpoint['AdamW'])\n",
        "    SGD.load_state_dict(checkpoint['SGD'])\n",
        "    AdamW_scheduler.load_state_dict(checkpoint['AdamW_scheduler'])\n",
        "    SGD_scheduler.load_state_dict(checkpoint['SGD_scheduler'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "During training, we need to validate on validation set and if validation error\n",
        "is better than the best, then save the new best model to a checkpoint\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def validate():\n",
        "    # run validation\n",
        "    mse_sum = torch.nn.MSELoss(reduction='sum')\n",
        "    total_mse = 0.0\n",
        "    count = 0\n",
        "    model.train(False)\n",
        "    with torch.no_grad():\n",
        "        for properties in validation:\n",
        "            species = properties['species'].to(device)\n",
        "            coordinates = properties['coordinates'].to(device).float()\n",
        "            true_energies = properties['energies'].to(device).float()\n",
        "            _, predicted_energies = model((species, coordinates))\n",
        "            total_mse += mse_sum(predicted_energies, true_energies).item()\n",
        "            count += predicted_energies.shape[0]\n",
        "    model.train(True)\n",
        "    return hartree2kcalmol(math.sqrt(total_mse / count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will also use TensorBoard to visualize our training process\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tensorboard = torch.utils.tensorboard.SummaryWriter()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the training loop, we need to compute force, and loss for forces\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training starting from epoch 1\n",
            "RMSE: 137.43297090775985 at epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 1: 100%|██████████| 4/4 [00:01<00:00,  2.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 154.2809847354662 at epoch 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 2: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s]\n"
          ]
        }
      ],
      "source": [
        "mse = torch.nn.MSELoss(reduction='none')\n",
        "\n",
        "print(\"training starting from epoch\", AdamW_scheduler.last_epoch + 1)\n",
        "# We only train 3 epoches here in able to generate the docs quickly.\n",
        "# Real training should take much more than 3 epoches.\n",
        "max_epochs = 3\n",
        "early_stopping_learning_rate = 1.0E-5\n",
        "force_coefficient = 0.1  # controls the importance of energy loss vs force loss\n",
        "best_model_checkpoint = 'force-training-best.pt'\n",
        "\n",
        "for _ in range(AdamW_scheduler.last_epoch + 1, max_epochs):\n",
        "    rmse = validate()\n",
        "    print('RMSE:', rmse, 'at epoch', AdamW_scheduler.last_epoch + 1)\n",
        "\n",
        "    learning_rate = AdamW.param_groups[0]['lr']\n",
        "\n",
        "    if learning_rate < early_stopping_learning_rate:\n",
        "        break\n",
        "\n",
        "    # checkpoint\n",
        "    if AdamW_scheduler.is_better(rmse, AdamW_scheduler.best):\n",
        "        torch.save(nn.state_dict(), best_model_checkpoint)\n",
        "\n",
        "    AdamW_scheduler.step(rmse)\n",
        "    SGD_scheduler.step(rmse)\n",
        "\n",
        "    tensorboard.add_scalar('validation_rmse', rmse, AdamW_scheduler.last_epoch)\n",
        "    tensorboard.add_scalar('best_validation_rmse', AdamW_scheduler.best, AdamW_scheduler.last_epoch)\n",
        "    tensorboard.add_scalar('learning_rate', learning_rate, AdamW_scheduler.last_epoch)\n",
        "\n",
        "    # Besides being stored in x, species and coordinates are also stored in y.\n",
        "    # So here, for simplicity, we just ignore the x and use y for everything.\n",
        "    for i, properties in tqdm.tqdm(\n",
        "        enumerate(training),\n",
        "        total=len(training),\n",
        "        desc=\"epoch {}\".format(AdamW_scheduler.last_epoch)\n",
        "    ):\n",
        "        species = properties['species'].to(device)\n",
        "        coordinates = properties['coordinates'].to(device).float().requires_grad_(True)\n",
        "        true_energies = properties['energies'].to(device).float()\n",
        "        true_forces = properties['forces'].to(device).float()\n",
        "        num_atoms = (species >= 0).sum(dim=1, dtype=true_energies.dtype)\n",
        "        _, predicted_energies = model((species, coordinates))\n",
        "\n",
        "        # We can use torch.autograd.grad to compute force. Remember to\n",
        "        # create graph so that the loss of the force can contribute to\n",
        "        # the gradient of parameters, and also to retain graph so that\n",
        "        # we can backward through it a second time when computing gradient\n",
        "        # w.r.t. parameters.\n",
        "        forces = -torch.autograd.grad(predicted_energies.sum(), coordinates, create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "        # Now the total loss has two parts, energy loss and force loss\n",
        "        energy_loss = (mse(predicted_energies, true_energies) / num_atoms.sqrt()).mean()\n",
        "        force_loss = (mse(true_forces, forces).sum(dim=(1, 2)) / num_atoms).mean()\n",
        "        loss = energy_loss + force_coefficient * force_loss\n",
        "\n",
        "        AdamW.zero_grad()\n",
        "        SGD.zero_grad()\n",
        "        loss.backward()\n",
        "        AdamW.step()\n",
        "        SGD.step()\n",
        "\n",
        "        # write current batch loss to TensorBoard\n",
        "        tensorboard.add_scalar('batch_loss', loss, AdamW_scheduler.last_epoch * len(training) + i)\n",
        "\n",
        "    torch.save({\n",
        "        'nn': nn.state_dict(),\n",
        "        'AdamW': AdamW.state_dict(),\n",
        "        'SGD': SGD.state_dict(),\n",
        "        'AdamW_scheduler': AdamW_scheduler.state_dict(),\n",
        "        'SGD_scheduler': SGD_scheduler.state_dict(),\n",
        "    }, latest_checkpoint)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ASE_ANI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
