{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __ASE SchNet implementation__\n",
    "This notebook contains the installation procedure and initial testing provided in the SchNetPack [GitHub](https://github.com/atomistic-machine-learning/schnetpack/tree/master) and the [documentation](https://schnetpack.readthedocs.io/en/latest/) for installing SchNet NNP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Installation procedure__\n",
    "Refer to ASE installation for the basics of the miniconda `venv` where MACE will be installed. This ensures that other calculators will not break the environment.\n",
    "- ASE installation process\n",
    "    - Create new conda environment (python 3.10 is standard). Check the Python requirement for the external calculator wanted. Usually  `python>3.9`.  \n",
    "    - `conda install ase` (installs `scipy` and `numpy` dependencies) and `conda install matplotlib`. \n",
    "    - Check the environment works installing `conda install pytest` and `ase test`.\n",
    "    - For ASE representations inside Jupyter Notebook, conda install `notebook`, `ipywidgets` and `nglview`. \n",
    "- SchNetPack installation process\n",
    "    - Clone base ASE environment. \n",
    "    - Install `pytorch>=1.9` via `conda install pytorch=2.2` (the flag pytorch=2.2 caused problems and had to install 2.5.1) and `pyTorchLightning` `conda install pytorchlightning`. **Note.** `pytorchlightning` was not found...\n",
    "    - Additional dependencies include `ase>=3.21` and `hydra>1.1.0` via `pip install hydra`. \n",
    "    - Visualization is compatible with `tensorboard`, `conda install tensorboard`. \n",
    "\n",
    "**Alternative installation.** Just use `pip install --upgrade schnetpack`, takes care of all the packages, but will make the venv completely unflexible. `pip install tensorboard`. \n",
    "\n",
    "**Testing.** To test the installation has been successful\n",
    "- Complete the [tutorials](https://github.com/atomistic-machine-learning/schnetpack/tree/master/examples/tutorials), or \n",
    "- Download the `tests` directory from the repo (install it in the conda `site-packages` folder of the venv `venv/x/lib/python3.10/site-packages`). Once propertly installed go to `/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/schnetpack` and run `pytest tests`. Check [here](https://github.com/atomistic-machine-learning/schnetpack/tree/master/tests) for more info. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SchNetPack CLI issue.** The CLI is based on Hydra and oriented on pytorch lightning. The template can be found [here](https://github.com/ashleve/lightning-hydra-template).  Note that in order to be able to use the SchNetPack CLI a training script called `spktrain` must be added to `$PATH`. I did not find that file nor was it added to path (the installation was through conda, it cannot escape the venv nor add things to `$PATH`)... \n",
    "\n",
    "As such CLI usage will be neglected, and only the ASE interface will be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### __References__\n",
    "\n",
    "Introductory tutorials for `SchNetPack` (via python/ASE interface) can be found in the [GitHub repo](https://github.com/atomistic-machine-learning/schnetpack/tree/master/examples/tutorials) and in the  [documentation](https://schnetpack.readthedocs.io/en/latest/tutorials/tutorial_01_preparing_data.html). Check the `schnetpack_tutorials` directory for the tutorials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __SchNetPack pretrained model. SchNet__\n",
    "SchNetPack provides a wide variety of [datasets](https://schnetpack.readthedocs.io/en/latest/api/datasets.html) which can be used to train models on organic molecules (e.g. ANI1 dataset) or on bulk materials (e.g. Materials Project dataset). Similarly to MACE, SchNetPack consists of pretrained models and code to train a model using SchNet architecture on some training dataset. \n",
    "\n",
    "Once a model has been trained on some dataset (see QM9 training tutorial), we can use it to evaluate the model and make predictions. Similarly to TorchANI, two separate ways of using the model exists \n",
    "- **SchNetPack (SPK) native usage** \n",
    "    - The `Trainer` object stores the best model in the model directory which can be loaded using pyTorch. Check [this documentation](https://schnetpack.readthedocs.io/en/latest/tutorials/tutorial_02_qm9.html) (Inference part) for more info. \n",
    "    - If the data (structures) is not SchNetPack format, we can define the structures as ASE `Atoms` and `AtomsConverter` from `spk`. \n",
    "\n",
    "- **Usage via ASE calculator.** \n",
    "    - Alternatively, we can use `SpkCalculator` as an interface to ASE. It requires a path to a trained model (SPK model), a neighbour list, and names and units of the properties used in the model (these consist of the inputs of the trained model). \n",
    "    - (kwargs) Precision and the device used can be controlled with `dtype` and `device`. \n",
    "    - **Note.** The calculator automatically converts the prediction of the given unit to internal ASE units (eV, Å, ...). \n",
    "\n",
    "    The `SpkCalculator` offers a simple way to perform all computations available in the ASE package via a trained model (provides the forcefield). This ASE computations include optimization, NMO and simple MD simulations.   \n",
    "\n",
    "Additional ASE interface info can be found in the documentation [Interface to ASE](https://schnetpack.readthedocs.io/en/latest/tutorials/tutorial_03_force_models.html#Interface-to-ASE), within tutorial 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ase imports\n",
    "from ase import units\n",
    "\n",
    "# import the calculators\n",
    "import schnetpack as spk\n",
    "\n",
    "#=======================#\n",
    "#       CALCULATORS     #   \n",
    "#=======================#\n",
    "\n",
    "calculator = spk.interfaces.SpkCalculator(\n",
    "    model_file=MODEL_PATH,                          # path to the pretrained model\n",
    "    neighbor_list=trn.ASENeighborList(cutoff=5.0),  # SchNetPack neighbor list\n",
    "    energy_key=MD17.energy,                         # name of energies in model\n",
    "    force_key=MD17.forces,                          # name of forces in model\n",
    "    energy_unit=\"kcal/mol\",                         # energy unit used by the model\n",
    "    position_unit=\"Ang\",                            # length unit used by the model\n",
    "    device='cpu'                                    # device used for calculations\n",
    "    dtype='float32'                                 # model precision \n",
    ")\n",
    "\n",
    "# the usage is the same as any other ASE calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __1. Training SchNet models__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1.1. Training a SchNet model on the QM9 training set.__\n",
    "References: Tutorial 1 and [Tutorial 2](https://schnetpack.readthedocs.io/en/latest/tutorials/tutorial_02_qm9.html) of the documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, first the train dataset must be preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import schnetpack as spk\n",
    "from schnetpack.datasets import QM9\n",
    "import schnetpack.transform as trn\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "qm9tut = './qm9tut'\n",
    "if not os.path.exists('qm9tut'):\n",
    "    os.makedirs(qm9tut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: split.npz: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading GDB-9 atom references...\n",
      "INFO:root:Done.\n",
      "INFO:root:Downloading GDB-9 data...\n",
      "INFO:root:Done.\n",
      "INFO:root:Extracting files...\n",
      "INFO:root:Done.\n",
      "INFO:root:Parse xyz files...\n",
      "100%|██████████| 133885/133885 [04:21<00:00, 511.63it/s]\n",
      "INFO:root:Write atoms to db...\n",
      "INFO:root:Done.\n",
      "100%|██████████| 10/10 [00:27<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "%rm split.npz\n",
    "\n",
    "qm9data = QM9(\n",
    "    './qm9.db',\n",
    "    batch_size=100,\n",
    "    num_train=1000,\n",
    "    num_val=1000,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=5.),\n",
    "        trn.RemoveOffsets(QM9.U0, remove_mean=True, remove_atomrefs=True),\n",
    "        trn.CastTo32()\n",
    "    ],\n",
    "    property_units={QM9.U0: 'eV'},\n",
    "    num_workers=1,\n",
    "    split_file=os.path.join(qm9tut, \"split.npz\"),\n",
    "    pin_memory=True,            # set to false, when not using a GPU\n",
    "    load_properties=[QM9.U0],   #only load U0 property\n",
    ")\n",
    "qm9data.prepare_data()\n",
    "qm9data.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that neighbors are collected using neighborlists. This is necessary for evaluating new (previously unseen) data for inference via an ASE calculator. Note that a cutoff is imposed to handle large molecules and PBCs (environment truncation, usage of locality). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reference calculations: 133885\n",
      "Number of train data: 1000\n",
      "Number of validation data: 1000\n",
      "Number of test data: 131885\n",
      "Available properties:\n",
      "- rotational_constant_A\n",
      "- rotational_constant_B\n",
      "- rotational_constant_C\n",
      "- dipole_moment\n",
      "- isotropic_polarizability\n",
      "- homo\n",
      "- lumo\n",
      "- gap\n",
      "- electronic_spatial_extent\n",
      "- zpve\n",
      "- energy_U0\n",
      "- energy_U\n",
      "- enthalpy_H\n",
      "- free_energy\n",
      "- heat_capacity\n"
     ]
    }
   ],
   "source": [
    "# DB info\n",
    "print('Number of reference calculations:', len(qm9data.dataset))\n",
    "print('Number of train data:', len(qm9data.train_dataset))\n",
    "print('Number of validation data:', len(qm9data.val_dataset))\n",
    "print('Number of test data:', len(qm9data.test_dataset))\n",
    "print('Available properties:')\n",
    "\n",
    "for p in qm9data.dataset.available_properties:\n",
    "    print('-', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties:\n",
      "- _idx : torch.Size([1])\n",
      "- energy_U0 : torch.Size([1])\n",
      "- _n_atoms : torch.Size([1])\n",
      "- _atomic_numbers : torch.Size([5])\n",
      "- _positions : torch.Size([5, 3])\n",
      "- _cell : torch.Size([1, 3, 3])\n",
      "- _pbc : torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "example = qm9data.dataset[0]\n",
    "print('Properties:')\n",
    "\n",
    "for k, v in example.items():\n",
    "    print('-', k, ':', v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U0 of hyrogen: -13.613121032714844 eV\n",
      "U0 of carbon: -1029.863037109375 eV\n",
      "U0 of oxygen: -2042.611083984375 eV\n"
     ]
    }
   ],
   "source": [
    "atomrefs = qm9data.train_dataset.atomrefs\n",
    "print('U0 of hyrogen:', atomrefs[QM9.U0][1].item(), 'eV')\n",
    "print('U0 of carbon:', atomrefs[QM9.U0][6].item(), 'eV')\n",
    "print('U0 of oxygen:', atomrefs[QM9.U0][8].item(), 'eV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model definition.** Once the data has been preprocessed, we must define the model architecture and the training (representation, optimization, regulation, etc.). The procedure is as follows:\n",
    "- Input modules to prepared the batched data before building the representation\n",
    "    - Calculation of pariwise distances\n",
    "\n",
    "- Representation\n",
    "    - SchNet (uses atom-wise features)\n",
    "\n",
    "- Output modules for property prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:209: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "# SchNet, 3 interaction layers, 5 Å coine cutoff, \n",
    "# pairwise distances expanded on 20 gaussians and \n",
    "# 50 atom-wise features and convolution filters\n",
    "\n",
    "# representation parameters\n",
    "cutoff = 5.\n",
    "n_atom_basis = 30\n",
    "\n",
    "pairwise_distance = spk.atomistic.PairwiseDistances()\n",
    "radial_basis = spk.nn.GaussianRBF(n_rbf=20, cutoff=cutoff)\n",
    "schnet = spk.representation.SchNet(\n",
    "    n_atom_basis=n_atom_basis, n_interactions=3,\n",
    "    radial_basis=radial_basis,\n",
    "    cutoff_fn=spk.nn.CosineCutoff(cutoff)\n",
    ")\n",
    "\n",
    "# atom-wise energy contributions are then summed\n",
    "# to predict the energy using an `Atomwise` module. \n",
    "pred_U0 = spk.atomistic.Atomwise(n_in=n_atom_basis, output_key=QM9.U0)\n",
    "\n",
    "\n",
    "# construct the NNP\n",
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=schnet,\n",
    "    input_modules=[pairwise_distance],\n",
    "    output_modules=[pred_U0],\n",
    "    postprocessors=[trn.CastTo64(), trn.AddOffsets(QM9.U0, add_mean=True, add_atomrefs=True)]\n",
    ")\n",
    "\n",
    "\n",
    "# output modules\n",
    "output_U0 = spk.task.ModelOutput(\n",
    "    name=QM9.U0,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=1.,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# task??\n",
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    outputs=[output_U0],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model.** Optimizer, callbacks, regulation, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name    | Type                   | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model   | NeuralNetworkPotential | 16.4 K | train\n",
      "1 | outputs | ModuleList             | 0      | train\n",
      "-----------------------------------------------------------\n",
      "16.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.4 K    Total params\n",
      "0.066     Total estimated model params size (MB)\n",
      "60        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:363: Skipping 'outputs' parameter because it is not possible to safely dump to YAML.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29cc053e9e6499d978297036df72ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82eee8f6ca3c4268918c4b505928cc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9468906d6f947c5861fe275fe0a5e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e75788faf34c1094791016f58b1215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d5e2c6483340cc81a99ee6b27d2f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir=qm9tut)\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(qm9tut, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='cpu',\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=qm9tut,\n",
    "    max_epochs=3, # for testing, we restrict the number of epochs\n",
    "\n",
    ")\n",
    "trainer.fit(task, datamodule=qm9data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference.** Once the model has been trained with the data, we can use the model for inference. The model is saved as `best_inference_model` when trained. A SpkCalculator can be defined with this model. This calculator interface makes sense if we want to predict the PES of a system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:schnetpack.interfaces.ase_interface:Loading model from ./qm9tut/best_inference_model\n",
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/schnetpack/utils/compatibility.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "qm9calculator = spk.interfaces.SpkCalculator(\n",
    "    model_file=os.path.join(qm9tut, \"best_inference_model\"),    # path to model\n",
    "    neighbor_list=trn.ASENeighborList(cutoff=5.),               # neighbor list\n",
    "    energy_key=QM9.U0,          # name of energy property in model\n",
    "    energy_unit=\"eV\",           # units of energy property\n",
    "    device='cpu',               # device for computation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1.2. Training a model on forces and energies (from an AIMD).__\n",
    "In this [tutorial](https://schnetpack.readthedocs.io/en/latest/tutorials/tutorial_04_molecular_dynamics.html), a SchNet model is trained on energies and forces using the MD17 ethanol dataset as an example. Then, the model performance is evaluated and geometry optimisation, normal mode analysis and basic molecular dynamic simulations are performed using the SchNetPack ASE interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import schnetpack as spk\n",
    "import schnetpack.transform as trn\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "forcetut = './forcetut'\n",
    "if not os.path.exists(forcetut):\n",
    "    os.makedirs(forcetut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, the MD17 ethanol dataset is loaded (same protocol as in QM9 tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading ethanol data\n",
      "INFO:root:Parsing molecule ethanol\n",
      "INFO:root:Write atoms to db...\n",
      "INFO:root:Done.\n",
      "100%|██████████| 100/100 [00:09<00:00, 10.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from schnetpack.datasets import MD17\n",
    "\n",
    "ethanol_data = MD17(\n",
    "    os.path.join(forcetut,'ethanol.db'),\n",
    "    molecule='ethanol',\n",
    "    batch_size=10,\n",
    "    num_train=1000,\n",
    "    num_val=1000,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=5.),\n",
    "        trn.RemoveOffsets(MD17.energy, remove_mean=True, remove_atomrefs=False),\n",
    "        trn.CastTo32()\n",
    "    ],\n",
    "    num_workers=1,\n",
    "    pin_memory=False, # set to false, when not using a GPU\n",
    ")\n",
    "ethanol_data.prepare_data()\n",
    "ethanol_data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded properties:\n",
      " _idx\n",
      " energy\n",
      " forces\n",
      " _n_atoms\n",
      " _atomic_numbers\n",
      " _positions\n",
      " _cell\n",
      " _pbc\n",
      "\n",
      "Forces:\n",
      " tensor([[ 1.4517e+00,  6.0192e+00,  5.2068e-07],\n",
      "        [ 1.7953e+01, -5.1624e+00,  3.4900e-07],\n",
      "        [-4.0884e+00,  2.2590e+01,  3.3088e-06],\n",
      "        [-1.1416e+00, -9.7469e+00,  7.6473e+00],\n",
      "        [-1.1416e+00, -9.7469e+00, -7.6473e+00],\n",
      "        [-2.4821e+00,  4.9335e+00,  4.3700e+00],\n",
      "        [-2.4821e+00,  4.9335e+00, -4.3700e+00],\n",
      "        [-5.5148e+00, -3.0207e+00, -8.9093e-09],\n",
      "        [-2.4393e+00, -1.0838e+01, -6.0721e-08]], dtype=torch.float64)\n",
      "Shape:\n",
      " torch.Size([9, 3])\n"
     ]
    }
   ],
   "source": [
    "# dataset info\n",
    "properties = ethanol_data.dataset[0]\n",
    "print('Loaded properties:\\n', *['{:s}\\n'.format(i) for i in properties.keys()])\n",
    "\n",
    "print('Forces:\\n', properties[MD17.forces])\n",
    "print('Shape:\\n', properties[MD17.forces].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset has been defined, we can define the model. As before, we must define the input modules, build the representation and define the output modules. Compared to the QM9 tutorial, this time we want to model forces (derivative of the energy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5.\n",
    "n_atom_basis = 30\n",
    "\n",
    "# input\n",
    "pairwise_distance = spk.atomistic.PairwiseDistances() # calculates pairwise distances between atoms\n",
    "radial_basis = spk.nn.GaussianRBF(n_rbf=20, cutoff=cutoff)\n",
    "\n",
    "# representation\n",
    "schnet = spk.representation.SchNet(\n",
    "    n_atom_basis=n_atom_basis, n_interactions=3,\n",
    "    radial_basis=radial_basis,\n",
    "    cutoff_fn=spk.nn.CosineCutoff(cutoff)\n",
    ")\n",
    "\n",
    "# output\n",
    "pred_energy = spk.atomistic.Atomwise(n_in=n_atom_basis, output_key=MD17.energy)\n",
    "pred_forces = spk.atomistic.Forces(energy_key=MD17.energy, force_key=MD17.forces)\n",
    "\n",
    "\n",
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=schnet,\n",
    "    input_modules=[pairwise_distance],\n",
    "    output_modules=[pred_energy, pred_forces],\n",
    "    postprocessors=[\n",
    "        trn.CastTo64(),\n",
    "        trn.AddOffsets(MD17.energy, add_mean=True, add_atomrefs=False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model has been defined, we can train the model. The loss function is comprised of a significant part force loss and another energy loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:209: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "output_energy = spk.task.ModelOutput(\n",
    "    name=MD17.energy,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=0.01,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")\n",
    "\n",
    "output_forces = spk.task.ModelOutput(\n",
    "    name=MD17.forces,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=0.99,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")\n",
    "\n",
    "# train task\n",
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    outputs=[output_energy, output_forces],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type                   | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model   | NeuralNetworkPotential | 16.4 K | train\n",
      "1 | outputs | ModuleList             | 0      | train\n",
      "-----------------------------------------------------------\n",
      "16.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.4 K    Total params\n",
      "0.066     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:363: Skipping 'outputs' parameter because it is not possible to safely dump to YAML.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517380d8b2264923ad2794ccab2c35d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a67c134465040749bc3b29033ce4055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc3596f7b7443c182e9a3968ad5c014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e6a01808b841cf90bc17b863b43237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8cde8ce2094599a71a97bc138430fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc524149a84e49508f1de297f56bfb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae3efa20f354096a9869eaac6cea3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=forcetut)\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(forcetut, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='cpu',\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=forcetut,\n",
    "    max_epochs=5, # for testing, we restrict the number of epochs\n",
    ")\n",
    "trainer.fit(task, datamodule=ethanol_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model trained, we can cast it to an ASE calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:schnetpack.interfaces.ase_interface:Loading model from ./forcetut/best_inference_model\n",
      "/Users/sergiortizropero/miniconda3/envs/ASE_schnet/lib/python3.10/site-packages/schnetpack/utils/compatibility.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ethanol_calc = spk.interfaces.SpkCalculator(\n",
    "    model_file=os.path.join(forcetut, \"best_inference_model\"),  # path to model\n",
    "    neighbor_list=trn.ASENeighborList(cutoff=5.0),              # neighbor list\n",
    "    energy_key=MD17.energy,         # name of energy property in model\n",
    "    force_key=MD17.forces,          # name of force property in model\n",
    "    energy_unit=\"kcal/mol\",         # unit of energy property\n",
    "    position_unit=\"Ang\",            # unit of length property\n",
    "    device='cpu',                   # device for computation \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __2. ASE SchNet calculator usage__\n",
    "Once a model has been trained on some dataset (see `qm9calculator` from the QM9 tutorial and the `md17calculator` from the ethanol dataset tutorial), we avaluate the model to make predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __EtOH single point calculation and atomization energy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EtOH energy @ SchNet-QM9:\t-4221.675 kcal/mol\n",
      "EtOH energy @ SchNet-MD17:\t-4215.754 kcal/mol\n"
     ]
    }
   ],
   "source": [
    "from ase import build\n",
    "atoms = build.molecule('CH3CH2OH')\n",
    "\n",
    "atoms.calc = qm9calculator\n",
    "qm9_etOH_energy = atoms.get_potential_energy()\n",
    "print(f'EtOH energy @ SchNet-QM9:\\t{qm9_etOH_energy:.3f} kcal/mol')\n",
    "\n",
    "atoms.calc = ethanol_calc\n",
    "md17_etOH_energy = atoms.get_potential_energy()\n",
    "print(f'EtOH energy @ SchNet-MD17:\\t{md17_etOH_energy:.3f} kcal/mol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2047.2430908083916, -1032.4109637737274, -18.46676814556122], [-468.2428506141119, -468.29980287254796, -468.2469250298014]]\n",
      "EtOH energy formation @ QM9-SchNet:\t1.191 [kcal/mol]\n",
      "EtOH energy formation @ MD17-SchNet:\t7.111 [kcal/mol]\n"
     ]
    }
   ],
   "source": [
    "# check the energy of formation of the H2O molecule\n",
    "calc_list = [qm9calculator, ethanol_calc]\n",
    "atomic_energies = []\n",
    "\n",
    "k = 0\n",
    "for calc_ in calc_list:\n",
    "    # define the atoms\n",
    "    atom_O = build.molecule('O')\n",
    "    atom_C = build.molecule('C')\n",
    "    atom_H = build.molecule('H')\n",
    "\n",
    "    atom_O.calc = calc_\n",
    "    atom_C.calc = calc_\n",
    "    atom_H.calc = calc_\n",
    "\n",
    "    energy_O = atom_O.get_potential_energy()\n",
    "    energy_C = atom_C.get_potential_energy()\n",
    "    energy_H = atom_H.get_potential_energy()\n",
    "    \n",
    "    atomic_energies.append([energy_O, energy_C, energy_H])\n",
    "\n",
    "    k += 0\n",
    "\n",
    "# check the results\n",
    "delta_E_formation_qm9 = qm9_etOH_energy - (atomic_energies[0][0] + 2 * atomic_energies[0][1] + 6 * atomic_energies[0][2])\n",
    "delta_E_formation_md17 = md17_etOH_energy - (atomic_energies[0][0] + 2 * atomic_energies[0][1] + 6 * atomic_energies[0][2])\n",
    "\n",
    "print(atomic_energies)\n",
    "print(f'EtOH energy formation @ QM9-SchNet:\\t{delta_E_formation_qm9:.3f} [kcal/mol]')\n",
    "print(f'EtOH energy formation @ MD17-SchNet:\\t{delta_E_formation_md17:.3f} [kcal/mol]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASE_schnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
