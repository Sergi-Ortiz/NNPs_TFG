{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __ASE MACE implementation__\n",
    "This notebook contains the installation procedure and initial testing provided in the MACE [GitHub](https://github.com/ACEsuit/mace?tab=readme-ov-file#pretrained-foundation-models) and the [documentation](https://mace-docs.readthedocs.io/en/latest/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Installation procedure__\n",
    "Refer to ASE installation for the basics of the miniconda `venv` where MACE will be installed. This ensures that other calculators will not break the environment.\n",
    "- ASE installation process\n",
    "    - Create new conda environment (python 3.10 is standard). Check the Python requirement for the external calculator wanted. Usually  `python>3.9`.  \n",
    "    - `conda install ase` (installs `scipy` and `numpy` dependencies) and `conda install matplotlib`. \n",
    "    - Check the environment works installing `conda install pytest` and `ase test`.\n",
    "    - For ASE representations inside Jupyter Notebook, conda install `notebook`, `ipywidgets` and `nglview`. \n",
    "- MACE installation process\n",
    "    - Clone base ASE environment. \n",
    "    - Install [pytorch](https://pytorch.org/get-started/locally/) using conda via `conda install pytorch=2.2 torchvision -c pytorch` (preferred over pip install). \n",
    "    - MACE cannot be installed via conda, so `pip install --upgrade pip` and then `pip install mace-torch`. **Obs.** MACE uses numpy 1.26 and not 2.x. When installing MACE it is downgraded but no issues arise. \n",
    "    - The MACE-MP model with dispersion corrections (D3), require `torch-dftd`, which can be installed via `pip install torch-dftd`. \n",
    "    - **Issue.** I have no clue why but the directory `foundations_models` inside `mace/calculators` is not present, and if ani-cc based MACE model is used, an error will show up 'no .model found'. Solution: use DownGit to manually download the models. **Update.** This does not solve the issue, the .model in the repo is designed for CUDA in mind, and as I dont have an NVIDIA gpu... [issue](https://github.com/ACEsuit/mace/issues/656). When training a model, `--save_cpu` to be able to use the trained model on CPU, else it defaults to CUDA. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __References__\n",
    "- MACE tutorials. Includes a model explanation and traning, evaluation examples. [RECOMMENDED]\n",
    "    - https://github.com/imagdau/Tutorials\n",
    "\n",
    "**Obs.** `mace.calculators` have the papers in the docstring, might be useful to know what paper to cite when using them. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __MACE pretrained models__\n",
    "MACE provides an interface to ASE via a calculator class named `MACECalculator`. Predefined calculators with specific models can be found in `mace.calculators`. Analyzing the `__init__`, we can see that MACE includes several pretrained foundational models in `foundations_models.py`. The `MACECalculator` class can be found in `mace.py` and includes a detailed description on its methods \n",
    "\n",
    "- `mace_anicc`\n",
    "    - Returns a MACECalculator object pretrained on the ANI CC dataset (H, C, N, O).\n",
    "    - Note that the name ANI-1ccx is reserved for the TorchANI implementation of the ANI model on the ANI CC dataset. \n",
    "    - Defaults to `device=cuda`.  \n",
    "\n",
    "- `mace_mp`\n",
    "    - Constructs a MACECalculator with a pretrained model based on the Materials Project (89 elements). The [MACE-MP models](https://github.com/ACEsuit/mace-mp) (available in the corresponding repo) include different training datasets, and model sizes, as well as certain architectural improvements depending on the model used. [Citations are available]. \n",
    "\n",
    "- `mace_off`\n",
    "    - Constructs a MACECalculator with a pretrained model based on the MACE-OFF23 models. The [MACE-OFF models](https://github.com/ACEsuit/mace-off) (available in the corresponding repo) are intended for organic molecules, and as such, would be interesting to compare to ANI-X models. \n",
    "\n",
    "As well as `MACECalculator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiortizropero/miniconda3/envs/ASE_all/lib/python3.10/site-packages/e3nn/o3/_wigner.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuequivariance or cuequivariance_torch is not available. Cuequivariance acceleration will be disabled.\n",
      "Using Materials Project MACE for MACECalculator with /Users/sergiortizropero/.cache/mace/20231203mace128L1_epoch199model\n",
      "Using float32 for MACECalculator, which is faster but less accurate. Recommended for MD. Use float64 for geometry optimization.\n",
      "Default dtype float32 does not match model dtype float64, converting models to float32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiortizropero/miniconda3/envs/ASE_all/lib/python3.10/site-packages/mace/calculators/mace.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TorchDFTD3Calculator for D3 dispersion corrections\n",
      "Using MACE-OFF23 MODEL for MACECalculator with /Users/sergiortizropero/.cache/mace/MACE-OFF23_medium.model\n",
      "Using float32 for MACECalculator, which is faster but less accurate. Recommended for MD. Use float64 for geometry optimization.\n",
      "Default dtype float32 does not match model dtype float64, converting models to float32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiortizropero/miniconda3/envs/ASE_all/lib/python3.10/site-packages/mace/calculators/mace.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# ase imports\n",
    "from ase import units\n",
    "\n",
    "# import the calculators\n",
    "from mace.calculators import mace_anicc, mace_mp, mace_off\n",
    "from mace.calculators import MACECalculator\n",
    "\n",
    "#=======================#\n",
    "#       CALCULATORS     #   \n",
    "#=======================#\n",
    "\n",
    "macemp = mace_mp(\n",
    "    # core parameters\n",
    "    device='cpu',               # 'cpu', 'cuda'\n",
    "    model='medium',             # path to the model, or size\n",
    "    default_dtype='float32', \n",
    "\n",
    "    # dispersion corrections\n",
    "    dispersion=True,                    # include D3 dispersion corrections. \n",
    "    damping='bj',                       # damping function associated with the D3 correction\n",
    "    dispersion_xc='pbe',                # exchange-correlation functional for D3 dispersion corrections\n",
    "    dispersion_cutoff=40.0*units.Bohr,  # cutoff radius in Bohr for D3 dispersion corrections\n",
    "    )\n",
    "\n",
    "maceoff = mace_off(\n",
    "    # core parameters\n",
    "    device='cpu',               # 'cpu', 'cuda'\n",
    "    model='medium',             # path to the model or size\n",
    "    default_dtype='float32', \n",
    ")\n",
    "\n",
    "# only CUDA\n",
    "#maceani = mace_anicc(\n",
    "#    # core parameters\n",
    "#    device='cpu',\n",
    "#    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __1. ASE MACE calculator usage__\n",
    "Basic tests with the pretrained models interfaced with ASE. Note that the MACE model based on the ANI-CC dataset is only available for CUDA and hence could not be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __H2O single point calculation and atomization energy__\n",
    "Comparison of two different calculators (MACE-MP and MACE-OFF models). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ase\n",
    "from ase import build\n",
    "\n",
    "# mace\n",
    "from mace.calculators import mace_mp, mace_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Materials Project MACE for MACECalculator with /Users/sergiortizropero/.cache/mace/20231203mace128L1_epoch199model\n",
      "Using float64 for MACECalculator, which is slower but more accurate. Recommended for geometry optimization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiortizropero/miniconda3/envs/ASE_all/lib/python3.10/site-packages/mace/calculators/mace.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MACE-OFF23 MODEL for MACECalculator with /Users/sergiortizropero/.cache/mace/MACE-OFF23_medium.model\n",
      "Using float64 for MACECalculator, which is slower but more accurate. Recommended for geometry optimization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiortizropero/miniconda3/envs/ASE_all/lib/python3.10/site-packages/mace/calculators/mace.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O energy @ MP (medium):\t-14.15936617752067\n",
      "H2O energy @ OFF (medium):\t-2081.11639716893\n"
     ]
    }
   ],
   "source": [
    "atoms = build.molecule('H2O')\n",
    "\n",
    "\n",
    "macemp = mace_mp(\n",
    "    model=\"medium\", \n",
    "    dispersion=False, \n",
    "    default_dtype=\"float64\", \n",
    "    device='cpu',\n",
    "    )\n",
    "\n",
    "maceoff = mace_off(\n",
    "    model=\"medium\", \n",
    "    device='cpu',\n",
    "    default_dtype='float64'\n",
    "    )\n",
    "\n",
    "atoms.calc = macemp\n",
    "macemp_H2O_energy = atoms.get_potential_energy()\n",
    "print(f'H2O energy @ MP (medium):\\t{macemp_H2O_energy}')\n",
    "\n",
    "atoms.calc = maceoff\n",
    "maceoff_H2O_energy = atoms.get_potential_energy()\n",
    "print(f'H2O energy @ OFF (medium):\\t{maceoff_H2O_energy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1589879653522117, -2.081460506806862], [-13.571964772646918, -2043.933693071156]]\n",
      "H2O energy formation @ MP (medium):\t-9.760 [units?]\n",
      "H2O energy formation @ OFF (medium):\t-10.039 [units?]\n",
      "H2O energy of water @ CCSD(T):\t\t-75.013 Hartree\n"
     ]
    }
   ],
   "source": [
    "# check the energy of formation of the H2O molecule\n",
    "calc_list = [macemp, maceoff]\n",
    "atomic_energies = []\n",
    "\n",
    "k = 0\n",
    "for calc_ in calc_list:\n",
    "    # define the atoms\n",
    "    atom_O = build.molecule('O')\n",
    "    atom_H = build.molecule('H')\n",
    "\n",
    "    atom_O.calc = calc_\n",
    "    atom_H.calc = calc_\n",
    "\n",
    "    energy_H = atom_H.get_potential_energy()\n",
    "    energy_O = atom_O.get_potential_energy()\n",
    "    atomic_energies.append([energy_H, energy_O])\n",
    "\n",
    "    k += 0\n",
    "\n",
    "# check the results\n",
    "delta_E_formation_MP = macemp_H2O_energy - (2 * atomic_energies[0][0] + atomic_energies[0][1])\n",
    "delta_E_formation_OFF = maceoff_H2O_energy - (2 * atomic_energies[1][0] + atomic_energies[1][1])\n",
    "\n",
    "print(atomic_energies)\n",
    "print(f'H2O energy formation @ MP (medium):\\t{delta_E_formation_MP:.3f} [units?]')\n",
    "print(f'H2O energy formation @ OFF (medium):\\t{delta_E_formation_OFF:.3f} [units?]')\n",
    "print(f'H2O energy of water @ CCSD(T):\\t\\t-75.013 Hartree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What energy units are the models predicting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __H2O MD NVT simulation__\n",
    "This simulation ([reference](https://mace-docs.readthedocs.io/en/latest/examples/foundation_examples.html)) uses the MACE-MP foundational model as NNP as the MD FF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Materials Project MACE for MACECalculator with /Users/sergiortizropero/.cache/mace/20231203mace128L1_epoch199model\n",
      "Using float32 for MACECalculator, which is faster but less accurate. Recommended for MD. Use float64 for geometry optimization.\n",
      "Default dtype float32 does not match model dtype float64, converting models to float32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiortizropero/miniconda3/envs/ASE_all/lib/python3.10/site-packages/mace/calculators/mace.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mace.calculators import mace_mp, mace_off, mace_anicc, MACECalculator\n",
    "from ase import build\n",
    "from ase.md import Langevin\n",
    "from ase.io.trajectory import Trajectory\n",
    "from ase.visualize import view\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from ase import units\n",
    "\n",
    "# MD settings\n",
    "T_init = 300 \n",
    "n_steps = 200\n",
    "\n",
    "macemp = mace_mp(\n",
    "    device='cpu', \n",
    "    model='medium', \n",
    "    default_dtype='float32',   \n",
    "    )\n",
    "\n",
    "atoms = build.molecule('H2O')\n",
    "atoms.calc = macemp\n",
    "\n",
    "MaxwellBoltzmannDistribution(atoms, temperature_K=T_init*units.kB)\n",
    "\n",
    "traj = Trajectory('water_nvt.traj', 'w', atoms)\n",
    "\n",
    "# NVT\n",
    "dyn = Langevin(atoms, 0.5 * units.fs, temperature_K=T_init*units.kB, friction=0.001)\n",
    "dyn.attach(traj.write, interval=1)\n",
    "dyn.run(n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f9b7bb316e43139834892bf745764a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cca4cafac354165a83f80e8d0e0b070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(NGLWidget(max_frame=200), VBox(children=(Dropdown(description='Show', options=('All', 'O', 'H')…"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj = Trajectory('water_nvt.traj')\n",
    "view(traj, viewer='ngl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __2. Training MACE models__\n",
    "While training models is not the ultimate goal, several examples on how to train and evaluate a MACE model with different datasets can be found [in the documentation](https://mace-docs.readthedocs.io/en/latest/examples/training_examples.html). Additional [tutorials](https://mace-docs.readthedocs.io/en/latest/examples/tutorials.html) are available, such as a [collab notebook](https://colab.research.google.com/drive/1ZrTuTvavXiCxTFyjBV4GqlARxgFwYAtX) for training and evaluating a model, and other tutorials for fine-tuning a pretrained model and MACE model theory. \n",
    "\n",
    "\n",
    "MACE offers the possibility to train a model within the MACE architecture given some training data. Extensive tutorials on how to train the model can be found [here](https://mace-docs.readthedocs.io/en/latest/examples/tutorials.html). A basic [introductory tutorial](https://colab.research.google.com/drive/1ZrTuTvavXiCxTFyjBV4GqlARxgFwYAtX) is provided.  \n",
    "\n",
    "**Simple run.** A simple training and MD run was performed in [this]() Collab Notebook, which corresponds to the [ASE calculator](https://mace-docs.readthedocs.io/en/latest/guide/ase.html) section of the documentation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASE_all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
